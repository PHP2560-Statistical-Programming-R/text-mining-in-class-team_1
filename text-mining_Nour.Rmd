---
title: "Text Analyis"
output: github_document
---
questions for analysis: 
1. what is the most important charecter based on how much is whas mentioned ? 
2. what is the most scariest book based on sentiment analysis ?
3. what the top ten used words in exception to stop words ?
4. sentiments by books 
5. sentiment by popularity based on "https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare" "
and the sixth question is unique for every student 



# Your mission


Perform text analysis.

## Okay, I need more information

Perform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.

## Okay, I need even more information.

Do the above. Can't think of a data source?

- `gutenbergr`
- `AssociatedPress` from the `topicmodels` package
- `NYTimes` or `USCongress` from the `RTextTools` package
- Harry Potter Complete 7 Books text
```{r} 

    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")}


devtools::install_github("bradleyboehmke/harrypotter")
    ```
- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/)
- Scrape tweets using [`twitteR`](https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/)

Analyze the text for sentiment OR topic. **You do not need to do both**. The datacamp courses and [Tidy Text Mining with R](http://tidytextmining.com/) are good starting points for templates to perform this type of analysis, but feel free to *expand beyond these examples*.

# Timelines and Task


We will spend the next 2 weeks working on analyzing textual data in R. You will do the following:

- Start with some text based data.
- Clean data and prepare it for analysis
- Ask questions about the data
- Answer these questions with the data using tables and graphics
- Each group member must have their own unique question that they code the answer for. 
```{r}
library(dplyr)
library(stringi)
library(harrypotter)
library(tidytext)
library(rebus)
```

```{r}
# tidying the text of the first book: 
  chamber_of_secrets_tidy <- data_frame( text = chamber_of_secrets, Book = "chamber_of_secrets") %>%
    unnest_tokens(sentence, text, token = "sentences") %>%
  mutate(line = row_number())
# tidy the second book 
deathly_hallows_tidy <- data_frame(text = deathly_hallows , Book = "deathly_hallows" ) %>%
unnest_tokens(sentence, text, token = "sentences") %>%
  mutate(line = row_number())
# the Third book
goblet_of_fire_tidy <- data_frame(text = goblet_of_fire, Book = "goblet_of_fire")%>%
unnest_tokens(sentence, text, token = "sentences") %>%
  mutate(line = row_number())
# the fourth book
half_blood_prince_tidy <- data_frame(text = half_blood_prince, Book = "half_blood_prince") %>%
  unnest_tokens(sentence, text, token = "sentences") %>%
  mutate(line = row_number())
# the fifth book 
order_of_the_phoenix_tidy <- data_frame(text = order_of_the_phoenix, Book = "order_of_the_phoenix") %>%
 unnest_tokens(sentence, text, token = "sentences") %>%
  mutate(line = row_number())
 # the sixth book 
philosophers_stone_tidy <- data_frame(text = philosophers_stone, Book = "philosophers_stone" ) %>%
unnest_tokens(sentence, text, token = "sentences") %>%
  mutate(line = row_number())
# the seventh book
prisoner_of_azkaban_tidy <- data_frame(text = prisoner_of_azkaban, Book = "prisoner_of_azkaban") %>%
unnest_tokens(sentence, text, token = "sentences") %>%
  mutate(line = row_number())
```

```{r}
# making one dataframe for all books 
harrypoter <- rbind(chamber_of_secrets_tidy, deathly_hallows_tidy, goblet_of_fire_tidy, half_blood_prince_tidy, order_of_the_phoenix_tidy, philosophers_stone_tidy, prisoner_of_azkaban_tidy) 
harrypoter
```
```{r}
#remove stop words that are unncessary for analysis like a, an , as ... etc. 
harrypoterclean <- harrypoter %>%
  unnest_tokens(word, sentence) %>%
  anti_join(stop_words)

```

```{r}
# making list of  the whole series characters: 
# after making a txt file from "https://en.wikipedia.org/wiki/List_of_Harry_Potter_characters" then importing to R 
 characters_raw <- readLines("characters_ weki.txt")
```
```{r}
# extracting names only based on pattern of two names start with an upper case and space between them.
# used capture to get first and last names seperatly into the data frame. 
characters_raw2 <- str_match( characters_raw, capture (UPPER %R% one_or_more(WRD)) %R% SPC %R% capture(UPPER %R% one_or_more(WRD)))
# excluding missing rows 
characters_raw3 <- as.data.frame( characters_raw2) %>%
  na.exclude() 
# naming colums 
colnames(characters_raw3)  <- c( "full name", "first", "last") 
# making sure no repetitions and names arranged alphabeticly.
characters_raw4 <- characters_raw3 %>%
  arrange(`full name`) %>%
unique() 
# renaming raws for ease of manual cleaning 
  rownames(characters_raw4) <- seq(length=nrow(characters_raw4))
# manually cleaning for non character names 
 characters_list <- characters_raw4[- c(41, 49, 58, 71, 161, 162,163), ]
 # renaming raws again 
rownames(characters_list) <- seq(length=nrow(characters_list))
# making colum named word for the sake of joining and analysis
 characters_list %>%
  mutate(word = first) %>%
 mutate_if(is.factor, as.character) -> characters_listjoin
   
  characters_listjoin$word <- str_replace_all(characters_listjoin$word , pattern = one_or_more(WRD), replacement = tolower)
  
```

Q1 what is the most important charecter based on how much is whas mentioned ? 
```{r}
 
 harrypoterclean %>%
inner_join( characters_listjoin, by = "word" ) %>%
count(Book, word,sort= TRUE)  
# not that joining and counting was done using first name only wich is not accurate. due to inability to use full name because  full names not always mentiond. also family name cannot be used becaue it is shared between many characters. 
```
Q2 what is the most scariest book based on sentiment analysis ?
```{r}
harrypoterclean %>%
  # joining with sentiment "bing"
  inner_join(get_sentiments("bing")) %>%
  group_by(Book) %>%
  count( Book, sentiment , sort = TRUE) %>%
  # filtering only negative sentiments
  filter(sentiment == "negative")
  # the most negative book is order_of_the_phoenix with 8774 negative word. 
```

```{r}
harrypoterclean %>%
  group_by(word) %>%
  count( word, sort = TRUE) %>%
arrange(desc(n))
# So the most imporatnt word by frequency of use is harry 
```