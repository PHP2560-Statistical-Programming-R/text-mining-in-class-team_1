---
title: "Text Analyis"
author: "Wei Wang"
date : "10/18/2017"
output: github_document
---




# Your mission

Perform text analysis.

## Okay, I need more information

Perform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.

## Okay, I need even more information.

Do the above. Can't think of a data source?

- `gutenbergr`
- `AssociatedPress` from the `topicmodels` package
- `NYTimes` or `USCongress` from the `RTextTools` package
- Harry Potter Complete 7 Books text
    ```
    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")
    ```
- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/)
- Scrape tweets using [`twitteR`](https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/)

Analyze the text for sentiment OR topic. **You do not need to do both**. The datacamp courses and [Tidy Text Mining with R](http://tidytextmining.com/) are good starting points for templates to perform this type of analysis, but feel free to *expand beyond these examples*.

# Timelines and Task


We will spend the next 2 weeks working on analyzing textual data in R. You will do the following:

- Start with some text based data.
- Clean data and prepare it for analysis
- Ask questions about the data
- Answer these questions with the data using tables and graphics
- Each group member must have their own unique question that they code the answer for. 


# Loading Data

```{r, message=FALSE, warning=FALSE}
packages <- c("wordcloud",
              "devtools",
              "tidyverse",
              "stringr",
              "tidytext",
              "dplyr",
              "reshape2",
              "igraph",
              "ggraph"
             )
install.packages(packages)

library(wordcloud)
library(devtools)
library(tidyverse)      
library(stringr)        
library(tidytext)
library(dplyr)
library(reshape2)
library(igraph)
library(ggraph)

    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")
```

# 1.Pre-processing

## 1.1 Shape the data and place all of the books in the Harry Potter series into a tibble. 
```{r}
hp_chapters <- c("Philosopher's Stone", 
            "Chamber of Secrets", 
            "Prisoner of Azkaban",
            "Goblet of Fire", 
            "Order of the Phoenix", 
            "Half-Blood Prince",
            "Deathly Hallows"
            )

hp_list <- list(harrypotter::philosophers_stone, 
                harrypotter::chamber_of_secrets, 
                harrypotter::prisoner_of_azkaban,
                harrypotter::goblet_of_fire, 
                harrypotter::order_of_the_phoenix, 
                harrypotter::half_blood_prince,
                harrypotter::deathly_hallows
                )
```

## 1.2 Tokenize the text into single words, strip away all punctuation and capitalization, and add columns to the tibble for the book and chapter.
```{r}
##Each book is an array in which each value in the array is a chapter 
series <- tibble()
for(i in seq_along(hp_chapters)) {
  
  temp <- tibble(chapter = seq_along(hp_list[[i]]),
                  text = hp_list[[i]]) %>%
    unnest_tokens(word, text) %>%
##Here I tokenize each chapter into words
    mutate(book = hp_chapters[i]) %>%
    select(book, everything())
  
  series <- rbind(series, temp)
}
```

## 1.3 Keep books in order of publication.
```{r}
series$book <- factor(series$book, levels = rev(hp_chapters))
series
```


# 2. Words in books
```{r}
series %>% count(word, sort = TRUE)
```
## 2.1 Find tf-idf

## 2.2 Topic Modeling






# 3. Sentiment analysis

## 3.1 Sentiment analysis by word

## 3.2 Sentiment analysis by message

## 3.3 N-gram analysis




# 4. Summary










