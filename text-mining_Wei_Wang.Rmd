---
title: "Text Analyis"
author: "Wei Wang"
date : "10/18/2017"
output: github_document
---




# Your mission

Perform text analysis.

## Okay, I need more information

Perform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.

## Okay, I need even more information.

Do the above. Can't think of a data source?

- `gutenbergr`
- `AssociatedPress` from the `topicmodels` package
- `NYTimes` or `USCongress` from the `RTextTools` package
- Harry Potter Complete 7 Books text
    ```
    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")
    ```
- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/)
- Scrape tweets using [`twitteR`](https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/)

Analyze the text for sentiment OR topic. **You do not need to do both**. The datacamp courses and [Tidy Text Mining with R](http://tidytextmining.com/) are good starting points for templates to perform this type of analysis, but feel free to *expand beyond these examples*.

# Timelines and Task


We will spend the next 2 weeks working on analyzing textual data in R. You will do the following:

- Start with some text based data.
- Clean data and prepare it for analysis
- Ask questions about the data
- Answer these questions with the data using tables and graphics
- Each group member must have their own unique question that they code the answer for. 


# Setup

```{r, message=FALSE, warning=FALSE}
# Load in packages.

library(wordcloud)
library(devtools)
library(tidyverse)      
library(stringr)        
library(tidytext)
library(dplyr)
library(reshape2)
library(igraph)
library(ggraph)
library(ggplot2)

    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")


# Vizualization settings.
theme_set(theme_light()) # set default ggplot theme to light
fs = 15 # default plot font size
```

# 1.Data preparation

## 1.1 Shape the data.
```{r, echo=TRUE}
hp_books <- c("Philosopher's Stone", 
            "Chamber of Secrets", 
            "Prisoner of Azkaban",
            "Goblet of Fire", 
            "Order of the Phoenix", 
            "Half-Blood Prince",
            "Deathly Hallows"
            )

hp_list <- list(harrypotter::philosophers_stone, 
                harrypotter::chamber_of_secrets, 
                harrypotter::prisoner_of_azkaban,
                harrypotter::goblet_of_fire, 
                harrypotter::order_of_the_phoenix, 
                harrypotter::half_blood_prince,
                harrypotter::deathly_hallows
                )
```

## 1.2 Place all of the books in the Harry Potter series into a tibble. Then tokenize the text into single words, strip away all punctuation and capitalization, and add columns to the tibble for the book and chapter.
```{r, echo=TRUE}
##Each book is an array in which each value in the array is a chapter 
series <- tibble()
for(i in seq_along(hp_books)) {
  
  temp <- tibble(book = seq_along(hp_list[[i]]),
                  text = hp_list[[i]]) %>%
    unnest_tokens(word, text) %>%
##Here I tokenize each chapter into words
    mutate(book = hp_books[i]) %>%
    select(book, everything())
  
  series <- rbind(series, temp)
}
```

## 1.3 Keep books in order of publication.
```{r}
series$book <- factor(series$book, levels = rev(hp_books))
series
```


# 2. Words in books
```{r}
used_words <- series %>% 
  count(word, sort = TRUE)
used_words
```
## 2.1 Plot word frequency per book.
```{r}
# PLOT WORD FREQUENCY PER BOOK
series %>%
  group_by(book, word) %>%
  anti_join(stop_words, by = "word") %>% # delete stopwords
  count() %>% # summarize count per word per book
  arrange(desc(n)) %>% # highest freq on top
  group_by(book) %>% # 
  mutate(top = seq_along(word)) %>% # identify rank within group
  filter(top <= 16) %>% # retain top 15 frequent words
  # create barplot
  ggplot(aes(x = -top, fill = book)) + 
  geom_bar(aes(y = n), stat = 'identity', col = 'black') +
  # make sure words are printed either in or next to bar
  geom_text(aes(y = ifelse(n > max(n) / 2, max(n) / 50, n + max(n) / 50),
                label = word), size = fs/3.5, hjust = "left") +
  theme(legend.position = 'none', # get rid of legend
        text = element_text(size = 8), # determine fontsize
        axis.text.x = element_text(angle = 45, hjust = 1, size = fs/1.5), # rotate x text
        axis.ticks.y = element_blank(), # remove y ticks
        axis.text.y = element_blank()) + # remove y text
  labs(y = "Word count", x = "", # add labels
       title = "Harry Plotter: Most frequent words throughout the saga") +
  facet_grid(. ~ book) + # separate plot for each book
  coord_flip() # flip axes

```


## 2.2 Find tf-idf.



## 2.3 Topic Modeling.






# 3. Sentiment analysis

## 3.1 Sentiment analysis by word.

## 3.2 Sentiment analysis by message.

## 3.3 N-gram analysis.




# 4. Summary










