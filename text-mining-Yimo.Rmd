---
title: "Text Analyis"
output: github_document
---




# Your mission

Perform text analysis.

## Okay, I need more information

Perform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.

## Okay, I need even more information.

Do the above. Can't think of a data source?

- `gutenbergr`
- `AssociatedPress` from the `topicmodels` package
- `NYTimes` or `USCongress` from the `RTextTools` package
- Harry Potter Complete 7 Books text
    ```{r}
    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")
    ```
- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/)
- Scrape tweets using [`twitteR`](https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/)

Analyze the text for sentiment OR topic. **You do not need to do both**. The datacamp courses and [Tidy Text Mining with R](http://tidytextmining.com/) are good starting points for templates to perform this type of analysis, but feel free to *expand beyond these examples*.

# Timelines and Task


We will spend the next 2 weeks working on analyzing textual data in R. You will do the following:

- Start with some text based data.
- Clean data and prepare it for analysis
- Ask questions about the data
- Answer these questions with the data using tables and graphics
- Each group member must have their own unique question that they code the answer for. 

# Group Question Sets
```{r}
## Questions for analysis: 
## 1. what is the most important charecter based on how much is whas mentioned ? 
## 2. what is the most scariest book based on sentiment analysis ?
## 3. what the top ten used words in exception to stop words ?
## 4. sentiments by books 
## 5. sentiment by popularity based on "https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare" 
# And the sixth question is unique for every student.
```

#0. Preperation
```{r}

    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")



library(devtools)
library(harrypotter)
library(rebus)
library(tidytext)
library(dplyr)
library(stringr)
library(stringi)
library(ggplot2)
library(tidyverse)
library(ggrepel)
library(grid)

theme = theme_minimal() + 
  theme(text = element_text(color = "gray15"),
        legend.position = c("top"),
        legend.direction = "horizontal",
        legend.justification = 0.3,
        legend.text = element_text(size = 15, color = "gray15"),
        axis.text = element_text(face = "italic"),
        axis.title.x = element_text(vjust = -10),
        axis.title.y = element_text(vjust = 2),
        axis.ticks.y = element_blank(),
        axis.line = element_line(color = "gray10", size = 0.6),
        axis.line.y = element_blank(),
        panel.grid.major = element_line(color = "gray15", size = 0.6),
        panel.grid.major.x = element_blank())

```



#1. Preperation
```{r}

#Function that adds columns called chapter, sentence, word and title, where word contain individual words in the novel, while sentence and chapter refers to the correpsonding chapter and sentence that the word appears, and book referes to the name of the book.



# Fetch Book metadata from theGuardian.com e.g publisher, ranking, sales, author e.t.c 
bookMetadata <- as_tibble(read.csv("https://docs.google.com/spreadsheets/d/1dhxblR1Vl7PbVP_mNhwEa3_lfUWiF__xSODLq1W83CA/export?format=csv&id=1dhxblR1Vl7PbVP_mNhwEa3_lfUWiF__xSODLq1W83CA&gid=0"))

harry_potter = "Harry Potter and the "
bookMetadata$Title  = bookMetadata$Title%>%
  str_replace_all(pattern = or(harry_potter, "'"), "")%>%
  str_replace_all(pattern = "-", " ")%>%
  str_to_title()


  

bookMetadata$Volume.Sales = bookMetadata$Volume.Sales%>%
  str_replace_all(pattern = ",", "")%>%
  as.numeric()

bookMetadata$Volume.Sales[bookMetadata$Title == "Half Blood Prince"] = bookMetadata$Volume.Sales[bookMetadata$Title == "Half Blood Prince"] + bookMetadata$Volume.Sales[bookMetadata$Title == "Half Blood Prince:childrens Edition" ]


date_pattern = ", " %R% capture(UPPER %R% one_or_more(WRD)) %R% SPC %R% capture(one_or_more(DGT)) %R% "," %R% SPC %R% capture(one_or_more(DGT))
bookMetadata = bookMetadata%>%
  mutate(year = as.numeric(str_match(bookMetadata$Publication.Date, pattern = date_pattern)[,4]))

#Function that adds columns called chapter, sentence, word and title, where word contain individual words in the novel, while sentence and chapter refers to the correpsonding chapter and sentence that the word appears, and book referes to the name of the book.
 book_tidy = function(name, title_name){
  chapter = tibble(text = get(name))
 #Add chapter
   pattern = one_or_more(one_or_more(UPPER) %R% optional(SPC) %R% optional("-"))
   pattern_chapter = capture(pattern) %R% SPC %R% SPC
   chapter_name = str_extract(get(name), pattern =pattern_chapter)
  chapter = tibble(text = get(name), chapter_name = chapter_name)%>%
      mutate(chapter = row_number())
 #Add sentence
    sentence = chapter%>%
      unnest_tokens(sentence, text, token = "sentences")%>%
      mutate(sentences = row_number())
  
 #Add word  
    df = sentence %>%
      unnest_tokens(word, sentence)
 #Add book
    title = tibble(book = title_name)
    return(cbind(title, df))
  }


names = c("philosophers_stone",
         "chamber_of_secrets",
         "prisoner_of_azkaban",
         "goblet_of_fire",
         "order_of_the_phoenix",
         "half_blood_prince",
         "deathly_hallows")

title_names = names%>%
  str_replace_all(pattern = "_", replacement = " ")%>%
  str_to_title()




harrypotter = rep(list(tibble()), 7)
harry_series = tibble()

#Save 7 books in a list, each in a tibble and remove the stop words.
for(i in 1:7){
  harrypotter[[i]] = book_tidy(names[i], title_names[i]) %>%
                     anti_join(stop_words)
 
}

#Save 7 books in a tibble and remove stop words.
for(i in 1:length(names)){
  harry_series = rbind(harry_series, book_tidy(names[i], title_names[i]))%>%
    anti_join(stop_words, by = "word")
}




whole_series = harry_series%>%
  inner_join(bookMetadata, by = c(book = "Title"))

for(i in 7:1){
  whole_series$book = relevel(as.factor(whole_series$book), ref = title_names[i])
}
```
#The name of main characters was found in website "https://en.wikipedia.org/wiki/List_of_Harry_Potter_characters", the content is simply copy and paste into local .txt document called characters.txt.
##1.2 Find the names of main characters and save them. The names of main characters were found in website 
```{r}
#"https://en.wikipedia.org/wiki/List_of_Harry_Potter_characters", the content is simply copy and paste into local document called "characters.txt".
  characters_txt = readLines("harry_potter_characters.txt")
#Define pattern
 pattern = "\t" %R% capture(UPPER %R% one_or_more(WRD)) %R% SPC %R% capture(UPPER %R% one_or_more(WRD))
 #Extract the names in the txt.
 characters = str_match(characters_txt, pattern = pattern)%>%
    as_tibble()%>%
    setNames(c("name", "first_name", "last_name"))%>%
   #Remove NA
    filter(!is.na(name))

 name = tibble(name = unique(c(characters$first_name, characters$last_name)))%>%
  #Add a column called lower, which is the names in lower case.
   mutate(lower = tolower(name))
```

#1. Freuquency analysis
```{r}

#Count the words



#Look for name frequency (except for Harry Potter) based on chapters.
name_chap_freq = whole_series%>%
  inner_join(name, by = c(word = "lower"))%>%
  count(book, word)%>%
  group_by(book)%>%
  top_n(5)%>%
  ungroup()%>%
  mutate(word = reorder(word, n))

ggplot(name_chap_freq, aes(x = word, y = n, fill = word))+
   geom_col() +
  facet_wrap(~book, scales = "free") +
  coord_flip()
 



#Look for words frequency for words that are not names based on each book.
word_freq = whole_series%>%
  anti_join(name, by = c(word = "lower"))%>%

```



#2. Sentiment analysis
##2.1 The scarest book
```{r}
emotion = get_sentiments("nrc")
sentiment = unique(emotion[,2])

total = whole_series%>%
  count(book)%>%
  rename(total_word = n)


scare_emotion = whole_series%>%
  left_join(total, by = "book")%>%
  inner_join(emotion, by = "word")%>%
  count(book, sentiment, total_word)%>%
  ungroup()%>%
  mutate(percent = n/total_word)%>%
  filter(sentiment == "fear")%>%
  arrange(desc(percent))


  ggplot(scare_emotion, aes(x = book, y = percent, fill = book))+
  geom_col()+
 theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
  
#Based on sentiment
  harry_sentiment = whole_series%>%
    inner_join(emotion, by = "word")%>%
    filter(sentiment != "positive" & sentiment != "negative")%>%
    count(book, year, sentiment)%>%
    arrange(year)
  
  ggplot(harry_sentiment, aes(sentiment, n, fill = sentiment))+
           geom_col()+
    facet_wrap(~book,  scales = "free_x")+
     theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
  #Count the word of anger
anger = whole_series%>%
  inner_join(emotion, by = "word")%>%
  filter(sentiment == "anger")
  


  

ggplot(emotion_in_chap, aes(x = chapter, y = contribution, fill = book))+
  geom_col()+
  facet_wrap(~book, scales = "free_x")

for(i in 7:1){
  
  whole_series$book = relevel(as.factor(whole_series$book), ref = names[i])
}
  
```
##2.2 Sentiment by popularity
```{r}
sentiment_by_popularity = whole_series%>%
  count(book, chapter, word)%>%
  inner_join(score, by = "word")%>%
  inner_join(bookMetadata, by = c(book = "Title"))%>%
  rename(sales = Volume.Sales)%>%
  arrange(year)%>%
  group_by(book, sales)%>%
  mutate(contribution = sum(n*score))%>%
  select(book, contribution, year, sales)%>%
  unique()%>%
  arrange(year)

 

ggplot(sentiment_by_popularity, aes(x = book, y = sales, fill = contribution), stat = "identity")+
  geom_col()+
  scale_x_discrete(limits= sentiment_by_popularity$book)+
  coord_flip()





```






